{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472bd6a2",
   "metadata": {},
   "source": [
    "# ANN: Regression (Website Traffic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe37e45",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ce46d1",
   "metadata": {},
   "source": [
    "First we do all installations and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a75e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e91780a",
   "metadata": {},
   "source": [
    "## Loads and process data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e7726",
   "metadata": {},
   "source": [
    "The csv file is loaded and we check the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d01f9ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Data/website_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad89c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Page Views', 'Session Duration', 'Bounce Rate', 'Traffic Source',\n",
       "       'Time on Page', 'Previous Visits', 'Conversion Rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "769e2245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Page Views', 'Session Duration', 'Bounce Rate',\n",
    "       'Time on Page', 'Previous Visits', 'Conversion Rate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10542c6b",
   "metadata": {},
   "source": [
    "With the code below, we try to take care of possble outliers from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b743885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "df = df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bc2304f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page Views</th>\n",
       "      <th>Session Duration</th>\n",
       "      <th>Bounce Rate</th>\n",
       "      <th>Time on Page</th>\n",
       "      <th>Previous Visits</th>\n",
       "      <th>Conversion Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>11.051381</td>\n",
       "      <td>0.230652</td>\n",
       "      <td>3.890460</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3.429316</td>\n",
       "      <td>0.391001</td>\n",
       "      <td>8.478174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.621052</td>\n",
       "      <td>0.397986</td>\n",
       "      <td>9.636170</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3.629279</td>\n",
       "      <td>0.180458</td>\n",
       "      <td>2.071925</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4.235843</td>\n",
       "      <td>0.291541</td>\n",
       "      <td>1.960654</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Page Views  Session Duration  Bounce Rate  Time on Page  Previous Visits  \\\n",
       "0           5         11.051381     0.230652      3.890460                3   \n",
       "1           4          3.429316     0.391001      8.478174                0   \n",
       "2           4          1.621052     0.397986      9.636170                2   \n",
       "3           5          3.629279     0.180458      2.071925                3   \n",
       "4           5          4.235843     0.291541      1.960654                5   \n",
       "\n",
       "   Conversion Rate  \n",
       "0              1.0  \n",
       "1              1.0  \n",
       "2              1.0  \n",
       "3              1.0  \n",
       "4              1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc27908",
   "metadata": {},
   "source": [
    "## X en y-variabelen definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb3ecbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Page Views', 'Bounce Rate', 'Previous Visits', 'Session Duration', 'Time on Page']]\n",
    "# X = df[['Bounce Rate', 'Time on Page',\n",
    "#         'Previous Visits', 'Conversion Rate']]\n",
    "y = df[['Conversion Rate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4761d16",
   "metadata": {},
   "source": [
    "## Optimal variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7e23da",
   "metadata": {},
   "source": [
    "We want to optimize the selection of used variables in the ANN. We use a correlation table to visualise the correlation between every variable. The correlations are a number between -1 and 1, high correlations can cause redundancy => overfitting, ineficiency, ... So the point of doing the following step is to see if we can leave one or more higly correlated variables behind before proceeding to the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c842c6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandasgui'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# !pip install pandasgui\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandasgui\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show\n\u001b[0;32m      4\u001b[0m correlations \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcorr()\n\u001b[0;32m      5\u001b[0m show(correlations)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandasgui'"
     ]
    }
   ],
   "source": [
    "# !pip install pandasgui\n",
    "from pandasgui import show\n",
    "\n",
    "correlations = df.corr()\n",
    "show(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee47b5ba",
   "metadata": {},
   "source": [
    "We can see from the grid that the highest correlation is 0.204, which is considered pretty weak. So there's no significant correlation between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013b0ae",
   "metadata": {},
   "source": [
    "Now in the next code part, let's go over feature importance using KBest selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e8450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# convert all continuous variables to integer,\n",
    "# and convert all negative numbers to 0\n",
    "X_cat = X.astype(int)\n",
    "X_cat = X_cat.clip(lower=0)\n",
    "\n",
    "# initialize chi2 and SelectKBest\n",
    "# Note: chi2 -test is a very common test\n",
    "# in statistics and quantitative analysis\n",
    "# basically it studies the data whether variables are related\n",
    "# or independent of each other\n",
    "chi_2_features = SelectKBest(chi2, k=len(X_cat.columns))\n",
    "\n",
    "# fit our data to the SelectKBest\n",
    "best_features = chi_2_features.fit(X_cat,y.astype(int))\n",
    "\n",
    "# use decimal format in table print later\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# wrap it up, and show the results\n",
    "# the higher the score, the more effect that column has on price\n",
    "df_features = pd.DataFrame(best_features.scores_)\n",
    "df_columns = pd.DataFrame(X_cat.columns)\n",
    "f_scores = pd.concat([df_columns,df_features],axis=1)\n",
    "f_scores.columns = ['Features','Score']\n",
    "f_scores.sort_values(by='Score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695420a4",
   "metadata": {},
   "source": [
    "From this output we can conclude that Session Duration and Time on Page are the two most important features who have the stronges relation with the target variable => Conversion Rate. It is weird that Bounce Rate gets a NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb14dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Bounce Rate'].isnull().sum())\n",
    "print(df['Bounce Rate'].nunique())\n",
    "# No weird output so that's strange..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be812aa0",
   "metadata": {},
   "source": [
    "## Test/train/validation-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afb9feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d589a9",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a8eea9",
   "metadata": {},
   "source": [
    "Now the fun part... creating the model. I started with a simple model with 3 layers, but the results were very bad. I tried a lot of different combinations, and even added Dropout layers, but the metrics are still very bad. We set the target variable to be \"Conversion Rate\", so that's the one we're predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4815af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(16, activation=\"relu\", input_shape=(5,)),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de2740f",
   "metadata": {},
   "source": [
    "## Start training of NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e688328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_train, y=y_train, epochs=400, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b4bd7d",
   "metadata": {},
   "source": [
    "## Training error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5c8ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcc1148",
   "metadata": {},
   "source": [
    "## Test/training data eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328e8a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test data evaluation:\")\n",
    "print(model.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"\\nTrain data evaluation:\")\n",
    "print(model.evaluate(X_train, y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53207993",
   "metadata": {},
   "source": [
    "## Get test predictions for evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60ac313",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "test_predictions = pd.Series(test_predictions.reshape(len(y_test),))\n",
    "pred_df = pd.DataFrame(np.asarray(y_test), columns=['Test True Y'])\n",
    "pred_df = pd.concat([pred_df, test_predictions], axis=1)\n",
    "pred_df.columns = ['Test True Y', 'Model Predictions']\n",
    "\n",
    "\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571086ca",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Test True Y', y='Model Predictions', data=pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d39a1c",
   "metadata": {},
   "source": [
    "## Error regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5955b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE - Mean average error\n",
    "print(\"MAE\")\n",
    "print(round(metrics.mean_absolute_error(y_test, test_predictions), 2), \"sec\")\n",
    "\n",
    "# MSE - Mean square error\n",
    "print(\"\\nMSE\")\n",
    "print(round(metrics.mean_squared_error(y_test, test_predictions), 2), \"sec^2\")\n",
    "\n",
    "# RMSE - Root mean square error\n",
    "print('\\nRMSE:')\n",
    "print(round(np.sqrt(metrics.mean_squared_error(y_test, test_predictions)), 2), \"sec\")\n",
    "\n",
    "# R-squared. 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "print('\\nR-squared:')\n",
    "print(round(metrics.r2_score(y_test, test_predictions), 2))\n",
    "\n",
    "# Explained Variance Score => 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "# high variance score = model is a good fit for the data \n",
    "# low variance score = model is not a good fit for the data\n",
    "# the higher the score, the model is more able to explain the variation in the data\n",
    "# if score is low, we might need more and better data\n",
    "print(\"\\nExplained variance score:\")\n",
    "print(round(metrics.explained_variance_score(y_test, test_predictions), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5a4c43",
   "metadata": {},
   "source": [
    "## Quick note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d8a408",
   "metadata": {},
   "source": [
    "So up until now I used Conversion Rate as the target variable. Seeing the results was very strange so I went looking at the values in the Conversion Rate column... they are almost all \"1\". So let's change the target variable. Knowing that Conversion Rate has very little variance in its values, we should also think about losing that variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576af4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Conversion Rate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a7ab48",
   "metadata": {},
   "source": [
    "So let's start over again in the \"part_2\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f2a60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
